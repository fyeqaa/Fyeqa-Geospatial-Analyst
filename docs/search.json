[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Berlin Park Accessibility\n\n\nSpatial distribution, accessibility, and equity of public parks across Berlin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContriBOT\n\n\nDetection and extraction of Author Contribution statements and ORCID from scientific papers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForest Fire Susceptibility\n\n\nAssessing Forest Fire Susceptibility and Its Impact on Biodiversity in Brandenburg Using Machine Learning and Climate Projections\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOil Spill Detection\n\n\nOil Spill detection in Tobago Island, Trinidad and Tobago Using SNAP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreeDetectR\n\n\nUrban Tree Detection from LiDAR in R\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/oil-spill-detection-snap.html",
    "href": "projects/oil-spill-detection-snap.html",
    "title": "Oil Spill Detection",
    "section": "",
    "text": "This project was carried out as part of the Microwave and Radar Sensing course.\n\nStudy Area\n\nLocation: Trinidad and Tobago\nEvent: Oil Spill on 7th February 2024\n\n\n\nData\n\nSource: Sentinel-1 SAR imagery downloaded from Copernicus Open Access Hub\nFocus: Region of interest around Trinidad and Tobago\n\n\n\nMethodology\nThis project was executed entirely using the ESA SNAP Toolbox with Sentinel-1 SAR imagery. All processing steps were performed through SNAP’s graphical interface (no custom code).\n\n1. Data Download\n\nDownloaded Sentinel-1 GRD data from Copernicus Open Access Hub\nSelected scenes around Trinidad and Tobago covering the date of the 7th February 2024 oil spill\n\n\n\n2. Subsetting\n\nUsed SNAP’s Subset Tool to spatially limit the imagery to the affected offshore area\nThis improved processing speed and focused the analysis on the region of interest\n\n\n\n3. Polarization Selection\n\nProcessed both VH and VV polarizations\nFound that VV polarization provided clearer contrast for oil slick detection\nUsed polarization comparison as part of result interpretation\n\n\n\n4. Preprocessing Steps\nFollowing the standard Sentinel-1 GRD preprocessing chain in SNAP:\n\nRadiometric Calibration\n\nConverted pixel values to backscatter coefficient (sigma naught)\n\nSpeckle Filtering\n\nApplied Lee Sigma filteR with the following configuration:\n\nFilter size: 7x7\nSigma: 0.9\nTarget window size: 3x3\n\nThis reduced granular SAR noise while preserving detail critical for oil slick detection\n\n\n\n\n5. Oil Spill Detection\n\nUsed SNAP’s built-in Oil Spill Detection Tool:\n\nDetected dark regions with reduced backscatter (common oil slick signature)\nApplied custom thresholding parameters within the tool\n\nMasked land areas to remove false positives and enhance accuracy\n\n\n\n6. Export and Visualization\n\nExported the final classified output as a GeoTIFF\n\n\n\nResults\n\nSuccessfully identified oil spill areas in Sentinel-1 imagery\nDemonstrated the effectiveness of radar remote sensing in monitoring maritime disasters\n\n\n\n\nSatelite Sar image\n\n\n\n\n\nSubset and Filtered sar image\n\n\n\n\n\nDetected Oil Spill\n\n\n\n\nTools & Software\n\nSNAP Toolbox (Sentinel Application Platform, ESA)\nSentinel-1 SAR Data\n\n\nProject Presentation\nOil Spill Detection - Presentation (PDF)"
  },
  {
    "objectID": "projects/ContriBOT.html",
    "href": "projects/ContriBOT.html",
    "title": "ContriBOT",
    "section": "",
    "text": "GitHub  \nThis project was developed in collaboration with the BIH QUEST Center for Responsible Research, where I worked as a working student focusing on text mining and scientific metadata extraction\nContriBOT is a text mining algorithm that parses a set of publications and detects which publications included Authorship Statements, Acknowledgements and ORCIDs.It is a tool that searches for typical section headings preceded by a section tag, in order to extract the author contribution and acknowledgement sections, as well as ORCID mentions. The extracted author contribution section can then be further screened and categorized, for example for following the CRediT taxonomy, or including actual author contributions\nMy Role\n\nDeveloped and optimized regex patterns for accurate detection of Author contributions statements and ORCID extraction\nContributed key functionalities to the ContriBOT R package to enhance metadata extraction\nCollaborated closely with the BIH QUEST Center research team\n\n\nInstallation\nThe latest version of the algorithm is structured as an R package and can easily be installed with the following command::\n# Install devtools if needed\n# install.packages(\"devtools\")\n\ndevtools::install_github(\"quest-bih/ContriBOT\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I’m Fyeqa",
    "section": "",
    "text": "Geospatial Data Scientist | Remote Sensing | Environmental ML \n\nI’m a Geospatial Data Scientist with extensive experience in Python and R, leveraging remote sensing platforms like Google Earth Engine and QGIS to analyze environmental challenges such as biodiversity loss and climate resilience. I apply machine learning models, spatial analysis, and data management to transform Earth Observation data into actionable insights.\nRecently, I conducted my Master’s thesis on assessing forest fire susceptibility and its impacts on biodiversity using machine learning and climate projection.I also contributed to two R packages focused on scientific metadata extraction and urban tree detection from LIDAR.\n\n\n  \n  \n Download CV \n Portfolio"
  },
  {
    "objectID": "projects/Berlin-park-accessibility.html",
    "href": "projects/Berlin-park-accessibility.html",
    "title": "Berlin Park Accessibility",
    "section": "",
    "text": "GitHub  \n\nSummary\nThis project investigates the distribution, accessibility, and equity of public parks across Berlin at both the district (Bezirk) and sub-district (Ortsteil) levels using geospatial data and 2024 population estimates. The analysis focuses on three main components:\n\nPark Availability: Counts the number of parks per administrative area.\nPark Area per Capita: Measures green space availability per resident to assess spatial equity.\nAccessibility (800m Buffer): Evaluates the share of each area within an 800-meter walking distance to a park.\n\nThe study uses spatial joins, area calculations, and buffer analysis to identify disparities in park access across the city. Results are presented through interactive maps and a detailed summary report, providing actionable insights to support equitable urban planning in Berlin.\n\n\nKey Findings\nDistricts like Spandau and Marzahn-Hellersdorf offer abundant park area per capita, densely populated areas such as Friedrichshain-Kreuzberg have limited green space. Nearly 38% of sub-districts lack any parks, revealing significant spatial disparities.These findings emphasize the need for targeted urban planning to promote equitable access to green spaces across Berlin.It highlights spatial inequalities in green space availability and park access. Interactive maps and detailed reports are included to support decision-making for equitable park development.\n\n\nOutputs\n\nDistrict map\nSubdistrict map\nReport"
  },
  {
    "objectID": "projects/Forest-Fire-Susceptibility.html",
    "href": "projects/Forest-Fire-Susceptibility.html",
    "title": "Forest Fire Susceptibility",
    "section": "",
    "text": "GitHub  \nThis Project is part of my Master’s Thesis at Technische Universität Berlin. The study investigates forest fire susceptibility in Brandenburg, Germany, using machine learning, explainable AI (XAI), and climate projections, while also evaluating the ecological risks to biodiversity within protected areas.\nThis project addresses:\n\nWhat are the primary drivers of forest fire susceptibility in Brandenburg?\nWhich biodiversity-rich protected areas are most at risk now and in the future?\nHow can Explainable AI (XAI) improve the interpretability of fire prediction models?\n\n\nMethodology\n\nData Sources\n\nForest fire occurrences (2016–2021)\nTopographic, vegetation, anthropogenic, and climatic predictors\nClimate projections for 2030 & 2050 under SSP5–8.5\nProtected areas datasets: Natura 2000, WDPA\n\n\n\nModeling Approach\n\nRandom Forest (RF): Classification model for forest fire susceptibility\nLOYO (Leave-One-Year-Out): Cross-validation strategy to assess temporal generalization\nFuture Projections: Fire prediction for summer seasons of 2030 & 2050\nExplainable AI:\n\nFeature importance using Gini\nLocal and global interpretation with SHAP values\n\n\n\n\nBiodiversity Risk Assessment\n\nSpatial overlay of high-risk fire zones and protected areas\nBuffer zone analysis to account for fire spread potential\nExposure trend comparison across 2021 → 2030 → 2050\n\n\n\n\nKey Results\n\nModel Performance\n\nHistorical (LOYO): ~66% accuracy, ROC-AUC: 0.717\nFuture scenarios: ~69% accuracy, ROC-AUC: 0.755\n\n\n\nMain Drivers\n\nProximity to railways and built-up areas\nForest type – especially Scots pine (coniferous)\nTemperature and precipitation had a secondary but relevant effect\n\n\n\nSpatial Insights\n\nSouthern Brandenburg identified as a persistent fire hotspot\n24% of protected areas overlap with high-susceptibility zones\nSpecial Protection Areas (SPAs) under the Birds Directive show growing vulnerability\n\n\n\n\nImplications\nThis work highlights the importance of integrated, adaptive fire management strategies that combine:\n\nNature-Based Solutions (NbS)\n\nMixed-species forests\nVegetated buffer zones\n\nPreventive Measures\n\nFirebreaks\nWetland restoration\nFuel load management\n\nPolicy Recommendations\n\nAlign fire risk planning with the **EU Biodiversity Strategy 2030\nTarget conservation efforts in high-risk zones\n\n\nThe framework developed here can be replicated in other fire-prone regions to assess ecological risks under future climate scenarios.\n\nThesis Document\nThesis PDF coming soon Code and data will be added later (pending permissions)"
  },
  {
    "objectID": "projects/TreeDetectR.html",
    "href": "projects/TreeDetectR.html",
    "title": "TreeDetectR",
    "section": "",
    "text": "GitHub  \nTreeDetectR is an R package I developed to detect and segment individual tree from urban LiDAR point cloud data. This project automates the processing steps, from raw LAS files to georeferenced tree locations. The goal of this project was to detect and segment individual trees within the university campus using FIS-Broker data’s LiDAR point cloud data.\nWhat I Did\n\nLoaded and filtered raw LiDAR data\nClassified ground points using the Cloth Simulation Filter (CSF)\nBuilt a Digital Terrain Model (DTM) and Canopy Height Model (CHM)\nDetected individual tree tops using local maximum filtering (LMF)\nSegmented individual trees using the Dalponte2016 algorithm\nExported georeferenced tree coordinates (X, Y, Z, Latitude, Longitude)\n\n\nVisual Results\nThis CHM represents the height of vegetation above ground level. Brighter areas are taller tree canopies.\n\n\n\nCHM\n\n\nRed dots represent tree tops detected using Local Maximum Filtering (LMF).\n\n\n\nTree Tops\n\n\n\n\nGeoreferenced Tree Coordinates\nTree coordinates were extracted and exported as a CSV file, including height and WGS84 (Lat/Lon) positions.\nSample of exported data:\n\n\n\nTree ID\nLongitude\nLatitude\nHeight (Z)\n\n\n\n\n001\n13.40123\n52.52041\n17.6\n\n\n002\n13.40128\n52.52046\n15.2\n\n\n003\n13.40131\n52.52050\n14.7\n\n\n\n\n\n\nSummary\nThis project demonstrates how to automate urban tree detection using LiDAR data in R. With TreeDetectR, users can go from raw point cloud to segmented, geolocated individual trees in just a few steps."
  }
]